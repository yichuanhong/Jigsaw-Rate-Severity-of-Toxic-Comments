{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dff2240f-1e64-4cd0-87b8-8243604b3236",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk, re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import ElasticNet, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "550ffaba-bf35-4cc9-a208-3579d8a32388",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('data/test.csv')\n",
    "train = pd.read_csv('data/train.csv')\n",
    "labels = pd.read_csv('data/test_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80e620c2-171b-401d-9fc7-7e46e040bb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total data\n",
    "df = train.merge(test, on=['id', 'comment_text'], how='left')\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c98da67-43d9-44f0-94ca-fc062f47ce9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check duplication\n",
    "sum(df[['id', 'comment_text']].duplicated())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f54b76ae-13a7-44ff-82a7-12717834418b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale up severe_toxic \n",
    "df['severe_toxic'] = df['severe_toxic'] * 2\n",
    "# sum features\n",
    "df['y'] = df[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].sum(axis=1)\n",
    "# normalization\n",
    "df['y'] = df['y']/df['y'].max()\n",
    "# rearrange df\n",
    "df = df[['comment_text', 'y']].rename(columns={'comment_text': 'text'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4245872e-0a83-4c60-9641-523f2c40f0f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159566</th>\n",
       "      <td>\":::::And for the second time of asking, when ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159567</th>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159568</th>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159569</th>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159570</th>\n",
       "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159571 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text    y\n",
       "0       Explanation\\nWhy the edits made under my usern...  0.0\n",
       "1       D'aww! He matches this background colour I'm s...  0.0\n",
       "2       Hey man, I'm really not trying to edit war. It...  0.0\n",
       "3       \"\\nMore\\nI can't make any real suggestions on ...  0.0\n",
       "4       You, sir, are my hero. Any chance you remember...  0.0\n",
       "...                                                   ...  ...\n",
       "159566  \":::::And for the second time of asking, when ...  0.0\n",
       "159567  You should be ashamed of yourself \\n\\nThat is ...  0.0\n",
       "159568  Spitzer \\n\\nUmm, theres no actual article for ...  0.0\n",
       "159569  And it looks like it was actually you who put ...  0.0\n",
       "159570  \"\\nAnd ... I really don't think you understand...  0.0\n",
       "\n",
       "[159571 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0e7dc7c-7e80-4fe2-bbc0-86902d1e9c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take first 80% comments as train data\n",
    "split_ratio = 0.2\n",
    "x, y = df['text'], df['y']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=split_ratio, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f813f11f-b0c6-4d3a-9a60-c0a9b964a7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download nltk data\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "476240f1-158e-4cff-8e72-82da7acc82b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a stopword library\n",
    "stopwords = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f7bb957-050f-4fe0-a8fb-292ec55b8a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "lmtzr = WordNetLemmatizer()\n",
    "\n",
    "def text_process(text):\n",
    "    tokens = []\n",
    "    # remove stopwords and only keep alphabetical words\n",
    "    for word in nltk.word_tokenize(text):\n",
    "        # replace 's, n't, 've\n",
    "        word = word.replace(\"'s'\", '').replace(\"n't\", ' not').replace(\"'ve\", ' have')\n",
    "        word = re.sub(r'[^a-zA-Z0-9 ]', '', word)\n",
    "        if word.lower() not in stopwords and word.isalpha():\n",
    "            tokens.append(word.lower())\n",
    "    \n",
    "    # lemmatize\n",
    "    return [lmtzr.lemmatize(token, 'v') for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c725d02c-4936-493d-afe1-eb51a926a9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tfidf matrix\n",
    "\n",
    "# max_df float or int, default=1.0\n",
    "# When building the vocabulary ignore terms that have a document frequency strictly higher than the given threshold \n",
    "# (corpus-specific stop words). If float in range [0.0, 1.0], the parameter represents a proportion of documents, integer \n",
    "# absolute counts. This parameter is ignored if vocabulary is not None.\n",
    "\n",
    "# min_df float or int, default=1\n",
    "# When building the vocabulary ignore terms that have a document frequency strictly lower than the given threshold. This \n",
    "# value is also called cut-off in the literature. If float in range of [0.0, 1.0], the parameter represents a proportion \n",
    "# of documents, integer absolute counts. This parameter is ignored if vocabulary is not None.\n",
    "\n",
    "# use_idf bool, default=True\n",
    "# Enable inverse-document-frequency reweighting. If False, idf(t) = 1.\n",
    "\n",
    "# tokenizer callable, default=None\n",
    "# Override the string tokenization step while preserving the preprocessing and n-grams generation steps. Only applies if \n",
    "# analyzer == 'word'.\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('bow', TfidfVectorizer(min_df=0.001, \n",
    "                            max_df=0.999, \n",
    "                            use_idf=True, \n",
    "                            analyzer=text_process, \n",
    "                            stop_words='english',\n",
    "                            ngram_range = (1,2))),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('elastic net', Ridge(alpha=1.0))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bdbb7f43-a40d-4d15-9b92-b6bb9990f4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df['text']\n",
    "y = df['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f6551e4c-5703-4d7f-b4a8-e5aab8e85fa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('bow',\n",
       "                 TfidfVectorizer(analyzer=<function text_process at 0x177953b80>,\n",
       "                                 max_df=0.999, min_df=0.001, ngram_range=(1, 2),\n",
       "                                 stop_words='english')),\n",
       "                ('tfidf', TfidfTransformer()), ('elastic net', Ridge())])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "24a315e3-fe81-44f8-a6ca-92920e57a556",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation = pd.read_csv('data/validation_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "33c55f8a-0cfc-42bf-927f-3b4dbcd6a21b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>worker</th>\n",
       "      <th>less_toxic</th>\n",
       "      <th>more_toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>313</td>\n",
       "      <td>This article sucks \\n\\nwoo woo wooooooo</td>\n",
       "      <td>WHAT!!!!!!!!?!?!!?!?!!?!?!?!?!!!!!!!!!!!!!!!!!...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>188</td>\n",
       "      <td>\"And yes, people should recognize that but the...</td>\n",
       "      <td>Daphne Guinness \\n\\nTop of the mornin' my fav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82</td>\n",
       "      <td>Western Media?\\n\\nYup, because every crime in...</td>\n",
       "      <td>\"Atom you don't believe actual photos of mastu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>347</td>\n",
       "      <td>And you removed it! You numbskull! I don't car...</td>\n",
       "      <td>You seem to have sand in your vagina.\\n\\nMight...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>539</td>\n",
       "      <td>smelly vagina \\n\\nBluerasberry why don't you ...</td>\n",
       "      <td>hey \\n\\nway to support nazis, you racist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30103</th>\n",
       "      <td>461</td>\n",
       "      <td>I'm sorry. I'm not an admin. I will give you t...</td>\n",
       "      <td>get out my large penis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30104</th>\n",
       "      <td>527</td>\n",
       "      <td>I'm sorry. I'm not an admin. I will give you t...</td>\n",
       "      <td>get out my large penis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30105</th>\n",
       "      <td>352</td>\n",
       "      <td>wow...\\nare you out of your mind, how was my e...</td>\n",
       "      <td>Piss off you slant eyed-gook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30106</th>\n",
       "      <td>311</td>\n",
       "      <td>wow...\\nare you out of your mind, how was my e...</td>\n",
       "      <td>Piss off you slant eyed-gook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30107</th>\n",
       "      <td>54</td>\n",
       "      <td>wow...\\nare you out of your mind, how was my e...</td>\n",
       "      <td>Piss off you slant eyed-gook</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30108 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       worker                                         less_toxic  \\\n",
       "0         313            This article sucks \\n\\nwoo woo wooooooo   \n",
       "1         188  \"And yes, people should recognize that but the...   \n",
       "2          82   Western Media?\\n\\nYup, because every crime in...   \n",
       "3         347  And you removed it! You numbskull! I don't car...   \n",
       "4         539   smelly vagina \\n\\nBluerasberry why don't you ...   \n",
       "...       ...                                                ...   \n",
       "30103     461  I'm sorry. I'm not an admin. I will give you t...   \n",
       "30104     527  I'm sorry. I'm not an admin. I will give you t...   \n",
       "30105     352  wow...\\nare you out of your mind, how was my e...   \n",
       "30106     311  wow...\\nare you out of your mind, how was my e...   \n",
       "30107      54  wow...\\nare you out of your mind, how was my e...   \n",
       "\n",
       "                                              more_toxic  \n",
       "0      WHAT!!!!!!!!?!?!!?!?!!?!?!?!?!!!!!!!!!!!!!!!!!...  \n",
       "1       Daphne Guinness \\n\\nTop of the mornin' my fav...  \n",
       "2      \"Atom you don't believe actual photos of mastu...  \n",
       "3      You seem to have sand in your vagina.\\n\\nMight...  \n",
       "4               hey \\n\\nway to support nazis, you racist  \n",
       "...                                                  ...  \n",
       "30103                             get out my large penis  \n",
       "30104                             get out my large penis  \n",
       "30105                       Piss off you slant eyed-gook  \n",
       "30106                       Piss off you slant eyed-gook  \n",
       "30107                       Piss off you slant eyed-gook  \n",
       "\n",
       "[30108 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0a1df5b2-be77-46e6-9488-736d8bdd4d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation['less_toxic_score'] = pipeline.predict(validation['less_toxic'])\n",
    "validation['more_toxic_score'] = pipeline.predict(validation['more_toxic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d43e8c26-6f98-40f3-bf32-95465c9ff7da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>worker</th>\n",
       "      <th>less_toxic</th>\n",
       "      <th>more_toxic</th>\n",
       "      <th>less_toxic_score</th>\n",
       "      <th>more_toxic_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>313</td>\n",
       "      <td>This article sucks \\n\\nwoo woo wooooooo</td>\n",
       "      <td>WHAT!!!!!!!!?!?!!?!?!!?!?!?!?!!!!!!!!!!!!!!!!!...</td>\n",
       "      <td>0.422244</td>\n",
       "      <td>0.027073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>188</td>\n",
       "      <td>\"And yes, people should recognize that but the...</td>\n",
       "      <td>Daphne Guinness \\n\\nTop of the mornin' my fav...</td>\n",
       "      <td>0.009274</td>\n",
       "      <td>0.160461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82</td>\n",
       "      <td>Western Media?\\n\\nYup, because every crime in...</td>\n",
       "      <td>\"Atom you don't believe actual photos of mastu...</td>\n",
       "      <td>-0.000397</td>\n",
       "      <td>0.016472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>347</td>\n",
       "      <td>And you removed it! You numbskull! I don't car...</td>\n",
       "      <td>You seem to have sand in your vagina.\\n\\nMight...</td>\n",
       "      <td>0.078383</td>\n",
       "      <td>0.385736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>539</td>\n",
       "      <td>smelly vagina \\n\\nBluerasberry why don't you ...</td>\n",
       "      <td>hey \\n\\nway to support nazis, you racist</td>\n",
       "      <td>0.002649</td>\n",
       "      <td>0.186877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30103</th>\n",
       "      <td>461</td>\n",
       "      <td>I'm sorry. I'm not an admin. I will give you t...</td>\n",
       "      <td>get out my large penis</td>\n",
       "      <td>0.070443</td>\n",
       "      <td>0.290369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30104</th>\n",
       "      <td>527</td>\n",
       "      <td>I'm sorry. I'm not an admin. I will give you t...</td>\n",
       "      <td>get out my large penis</td>\n",
       "      <td>0.070443</td>\n",
       "      <td>0.290369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30105</th>\n",
       "      <td>352</td>\n",
       "      <td>wow...\\nare you out of your mind, how was my e...</td>\n",
       "      <td>Piss off you slant eyed-gook</td>\n",
       "      <td>0.013450</td>\n",
       "      <td>0.209693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30106</th>\n",
       "      <td>311</td>\n",
       "      <td>wow...\\nare you out of your mind, how was my e...</td>\n",
       "      <td>Piss off you slant eyed-gook</td>\n",
       "      <td>0.013450</td>\n",
       "      <td>0.209693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30107</th>\n",
       "      <td>54</td>\n",
       "      <td>wow...\\nare you out of your mind, how was my e...</td>\n",
       "      <td>Piss off you slant eyed-gook</td>\n",
       "      <td>0.013450</td>\n",
       "      <td>0.209693</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30108 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       worker                                         less_toxic  \\\n",
       "0         313            This article sucks \\n\\nwoo woo wooooooo   \n",
       "1         188  \"And yes, people should recognize that but the...   \n",
       "2          82   Western Media?\\n\\nYup, because every crime in...   \n",
       "3         347  And you removed it! You numbskull! I don't car...   \n",
       "4         539   smelly vagina \\n\\nBluerasberry why don't you ...   \n",
       "...       ...                                                ...   \n",
       "30103     461  I'm sorry. I'm not an admin. I will give you t...   \n",
       "30104     527  I'm sorry. I'm not an admin. I will give you t...   \n",
       "30105     352  wow...\\nare you out of your mind, how was my e...   \n",
       "30106     311  wow...\\nare you out of your mind, how was my e...   \n",
       "30107      54  wow...\\nare you out of your mind, how was my e...   \n",
       "\n",
       "                                              more_toxic  less_toxic_score  \\\n",
       "0      WHAT!!!!!!!!?!?!!?!?!!?!?!?!?!!!!!!!!!!!!!!!!!...          0.422244   \n",
       "1       Daphne Guinness \\n\\nTop of the mornin' my fav...          0.009274   \n",
       "2      \"Atom you don't believe actual photos of mastu...         -0.000397   \n",
       "3      You seem to have sand in your vagina.\\n\\nMight...          0.078383   \n",
       "4               hey \\n\\nway to support nazis, you racist          0.002649   \n",
       "...                                                  ...               ...   \n",
       "30103                             get out my large penis          0.070443   \n",
       "30104                             get out my large penis          0.070443   \n",
       "30105                       Piss off you slant eyed-gook          0.013450   \n",
       "30106                       Piss off you slant eyed-gook          0.013450   \n",
       "30107                       Piss off you slant eyed-gook          0.013450   \n",
       "\n",
       "       more_toxic_score  \n",
       "0              0.027073  \n",
       "1              0.160461  \n",
       "2              0.016472  \n",
       "3              0.385736  \n",
       "4              0.186877  \n",
       "...                 ...  \n",
       "30103          0.290369  \n",
       "30104          0.290369  \n",
       "30105          0.209693  \n",
       "30106          0.209693  \n",
       "30107          0.209693  \n",
       "\n",
       "[30108 rows x 5 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca089ae-b565-4a26-a8e2-5af554966cb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
